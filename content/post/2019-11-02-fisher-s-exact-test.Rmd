---
title: Fisherâ€™s Exact Test
author: Kyle Webb
date: '2019-11-02'
slug: fisher-s-exact-test
categories:
  - statistics
tags:
  - statistics
subtitle: ''
description: 'A case study and power analysis for a common statistical test in medicine'
image: ''
---

Fisher's exact test is a common statistical test implemented for count data in a contingency table. The name gets the term *exact* from the fact that the test compares group counts to the hypergeometric function and thus returns an exact probability of obtaining counts of different outcomes. 

As an example, let's consider a hypothetical study of mice evenly split into two groups-- a control group and a treatment group. The treated mice will receive a vaccine before infection while the control group will not. After two weeks, the live and dead mice are tallied for each group. We are interested in whether vaccine treatment has any effect on mouse mortality.

```{r mouse_table}
library(kableExtra)
mouse_df = data.frame('Alive' = c(10, 19), 'Dead' = c(10, 1)) 
rownames(mouse_df) = c('Control', 'Treatment')

kable(mouse_df) %>% 
  row_spec(1:2, bold = TRUE)
```

Notice that we can compute marginal counts from the contingency table associated for each of the levels of interest: 20 control mice ($C$) and 20 treated mice ($T$) as well as 29 live mice ($A$) and 11 dead mice ($D$) with 40 mice studied in total ($N$). For all intents and purposes, we'll label a living mouse as a success for the study and a dead mouse as a failure (though I'm sure some may like to have it the other way round).

One way to state our null hypothesis for this study would be to say $H_{0} : P(A|C) > P(A|T)$, which states that the probability of a living mouse from the control group is greater than the probability of a living mouse from the treatment group. 

I've mentioned before that the Fisher's exact test compares contingency table data to a hypergeometric probability mass function. This distribution is shown below where we will use labels from above to represent the probability of observing alive mice ($A$).

$P(A | C, D, T, N) = \frac{\binom{C}{A|C}\binom{T}{A|T}}{\binom{N}{A}} =   \frac{\binom{20}{10}\binom{20}{19}}{\binom{40}{29}} \approx 7.3 * 10 ^{-4}$

Here $\binom{n}{k}$ is the binomial coefficient where $\binom{n}{k} = \frac{n!}{(n-k)!k!}$, showing all the ways to pick $k$ unordered combinations for $n$ possible values. 

In order to obtain a p-value from this experiment we can compute the probability under more extreme cases then our own and then sum up these probabilites:

$P(A \geq 19| C, D, T, N) = \frac{\binom{20}{10}\binom{20}{19}}{\binom{40}{29}} + \frac{\binom{20}{9}\binom{20}{20}}{\binom{40}{29}}
\approx 0.0017$.

This is the same output you would obtain from the one-sided fisher's exact test in R:

```{r fisher_test}
fish_test = fisher.test(mouse_df, alternative = "less")
fish_test$p.value
```

While this is all fine and dandy, it assumes we know what error rate and sample size to use for our experiment in the first place. Power analyses are used to detect the probability of true significant effect when certain experimental considerations are implemented. A power analysis is also helpful for sample size calculations if, for instance, the experimenter has time and budget constraints and therefore needs to know how many samples to collect for their study. For this example, I'll consider the same null hypothesis with a type 1 error rate of 0.05 (the probability of falsely detecting a treatment effect). 

In order to perform the power analysis, I'll need to simulate random binomials for the treatment group and control group. I'll specify treatment group sample size and control group sample size as the same number ($n$) with probabilities for surviving mice in each group ($p_t$ for the treatment group and $p_c$ for the control group). For the purposes of this illustration, I'll assume the control group and treatment probabilities are 0.5 and 0.9 ($p_c = 0.5$ and $p_t = 0.9$). 

```{r power_analysis, eval = FALSE}
n = 30
p_c =  0.5
p_t = 0.9
alpha = 0.05

n_sims = 1000
sims_c = matrix(0, n_sims, n)
sims_t = matrix(0, n_sims, n)

power_vals = c()

for(i in 1:(n-1)){
  s = i + 1
  sims_c[,i] = rbinom(n_sims, size = s, prob = p_c) # simulated alive control mice
  sims_t[,i] = rbinom(n_sims, size = s, prob = p_t) # simulated alive treatment mice
  sims2 = cbind(sims_c[,i], sims_t[,i], s - sims_c[,i], s - sims_t[,i]) # (A|C, A|T, n - A|C, n - A|T)
  test = apply(sims2, 1, 
               function(r) fisher.test(matrix(r, 2, 2), alternative = 'less')$p.value)
  power_vals[i] = mean(test < alpha)
}
```


Below we can see the results of the power analysis considering different type 1 error rates (alpha). 

```{r setup, include = FALSE, eval = FALSE}
power_vals = data.frame(size = rep(2:30, 3),
                        vals = c(power_vals_10, power_vals_5, power_vals_1), 
                        alpha = c(rep('0.1', 29), rep('0.05', 29), rep('0.01', 29)))

ggplot(power_vals, aes(x = size, y = vals, col = alpha)) + 
    geom_point() + theme_bw() + 
    ylab('Power') +
    theme(panel.grid.minor = element_blank()) +
    scale_x_continuous(breaks = seq(2, 30, by = 2)) +
    scale_y_continuous(breaks = seq(0, 1, by = .1)) +
    ggtitle("Fisher Exact Test Power Curves")
```

![](/post/2019-11-02-fisher-s-exact-test_files/power_curves.png)

